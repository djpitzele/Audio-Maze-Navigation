{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: Interactive Simulation Demo\n",
    "\n",
    "This notebook demonstrates the trained agent navigating through a maze using only acoustic signals.\n",
    "\n",
    "## Demo Features\n",
    "\n",
    "1. Load trained model\n",
    "2. Generate test maze\n",
    "3. Run agent navigation using acoustic perception\n",
    "4. Visualize trajectory and compare with optimal path\n",
    "5. Analyze performance metrics\n",
    "\n",
    "## How It Works\n",
    "\n",
    "At each step:\n",
    "1. Agent emits sound pulse\n",
    "2. k-Wave simulates acoustic propagation and reflections\n",
    "3. Microphone array captures reverberations\n",
    "4. CNN processes spectrogram and predicts action\n",
    "5. Agent moves based on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "from src.simulation import AcousticSimulator\n",
    "from src.environment import MazeGenerator, Oracle, Action\n",
    "from src.model import AudioNavCNN\n",
    "from src.utils import (\n",
    "    plot_maze,\n",
    "    plot_navigation_episode,\n",
    "    plot_multi_channel_spectrogram,\n",
    "    create_animation_frames\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path\n",
    "MODEL_PATH = '../data/audio_nav_model.pth'\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "# Extract configuration\n",
    "model_config = checkpoint['model_config']\n",
    "normalization = checkpoint['normalization']\n",
    "performance = checkpoint['performance']\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"  Microphones: {model_config['num_microphones']}\")\n",
    "print(f\"  Actions: {model_config['num_actions']}\")\n",
    "print(f\"  Dropout: {model_config['dropout_rate']}\")\n",
    "\n",
    "print(\"\\nNormalization:\")\n",
    "print(f\"  Mean: {normalization['mean']:.6f}\")\n",
    "print(f\"  Std: {normalization['std']:.6f}\")\n",
    "\n",
    "print(\"\\nTraining Performance:\")\n",
    "print(f\"  Best epoch: {performance['best_epoch']}\")\n",
    "print(f\"  Validation accuracy: {performance['final_val_accuracy']:.2f}%\")\n",
    "\n",
    "# Create and load model\n",
    "model = AudioNavCNN(\n",
    "    num_microphones=model_config['num_microphones'],\n",
    "    num_actions=model_config['num_actions'],\n",
    "    dropout_rate=model_config['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n✓ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment configuration\n",
    "MAZE_WIDTH = 20\n",
    "MAZE_HEIGHT = 20\n",
    "RANDOM_SEED = 123  # Different from training\n",
    "\n",
    "# Acoustic parameters (should match training)\n",
    "GRID_SPACING = 0.01\n",
    "SIMULATION_DURATION = 0.015\n",
    "SOURCE_FREQUENCY = 5000.0\n",
    "NUM_MICROPHONES = 8\n",
    "\n",
    "# Navigation parameters\n",
    "MAX_STEPS = 100  # Maximum steps before termination\n",
    "\n",
    "print(\"Test Environment Configuration:\")\n",
    "print(f\"  Maze size: {MAZE_WIDTH}×{MAZE_HEIGHT}\")\n",
    "print(f\"  Max steps: {MAX_STEPS}\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Test Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate maze\n",
    "maze_gen = MazeGenerator(MAZE_WIDTH, MAZE_HEIGHT, random_seed=RANDOM_SEED)\n",
    "maze = maze_gen.generate_simple_maze(wall_probability=0.3)\n",
    "\n",
    "print(f\"Maze shape: {maze.shape}\")\n",
    "print(f\"Walkable cells: {(maze == 0).sum()}\")\n",
    "\n",
    "# Initialize oracle (for comparison)\n",
    "oracle = Oracle(maze)\n",
    "\n",
    "# Select random start and goal positions\n",
    "start_pos = maze_gen.get_random_walkable_position(maze)\n",
    "goal_pos = maze_gen.get_random_walkable_position(maze)\n",
    "\n",
    "# Ensure goal is reachable from start\n",
    "while not oracle.is_reachable(start_pos, goal_pos) or start_pos == goal_pos:\n",
    "    goal_pos = maze_gen.get_random_walkable_position(maze)\n",
    "\n",
    "# Fixed sound source position\n",
    "source_pos = maze_gen.get_random_walkable_position(maze)\n",
    "\n",
    "print(f\"\\nStart position: {start_pos}\")\n",
    "print(f\"Goal position: {goal_pos}\")\n",
    "print(f\"Source position: {source_pos}\")\n",
    "\n",
    "# Compute optimal path\n",
    "optimal_path = oracle.find_path(start_pos, goal_pos)\n",
    "print(f\"Optimal path length: {len(optimal_path)} steps\")\n",
    "\n",
    "# Visualize\n",
    "fig = plot_maze(\n",
    "    maze,\n",
    "    agent_pos=start_pos,\n",
    "    goal_pos=goal_pos,\n",
    "    source_pos=source_pos,\n",
    "    path=optimal_path,\n",
    "    title=\"Test Maze with Optimal Path\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Acoustic Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simulator\n",
    "simulator = AcousticSimulator(\n",
    "    grid_spacing=GRID_SPACING,\n",
    "    simulation_duration=SIMULATION_DURATION,\n",
    "    source_frequency=SOURCE_FREQUENCY,\n",
    "    num_microphones=NUM_MICROPHONES,\n",
    "    pml_size=10,\n",
    ")\n",
    "\n",
    "print(\"✓ Acoustic simulator initialized\")\n",
    "print(f\"  Grid spacing: {GRID_SPACING} m\")\n",
    "print(f\"  Simulation duration: {SIMULATION_DURATION*1000} ms\")\n",
    "print(f\"  Source frequency: {SOURCE_FREQUENCY} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Navigation Episode\n",
    "\n",
    "The agent will navigate from start to goal using only acoustic perception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action names\n",
    "action_names = ['STOP', 'UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "action_deltas = {\n",
    "    Action.STOP: (0, 0),\n",
    "    Action.UP: (-1, 0),\n",
    "    Action.DOWN: (1, 0),\n",
    "    Action.LEFT: (0, -1),\n",
    "    Action.RIGHT: (0, 1),\n",
    "}\n",
    "\n",
    "# Initialize navigation\n",
    "current_pos = start_pos\n",
    "trajectory = [current_pos]\n",
    "actions_taken = []\n",
    "spectrograms_history = []\n",
    "\n",
    "reached_goal = False\n",
    "step = 0\n",
    "\n",
    "print(\"Starting navigation...\\n\")\n",
    "print(\"⚠️ Each step requires a k-Wave simulation (~30-60 seconds)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Navigation loop\n",
    "for step in range(MAX_STEPS):\n",
    "    print(f\"\\nStep {step + 1}/{MAX_STEPS}\")\n",
    "    print(f\"  Current position: {current_pos}\")\n",
    "    \n",
    "    # Check if goal reached\n",
    "    if current_pos == goal_pos:\n",
    "        print(\"  ✓ GOAL REACHED!\")\n",
    "        reached_goal = True\n",
    "        break\n",
    "    \n",
    "    # Run acoustic simulation\n",
    "    print(\"  Running k-Wave simulation...\")\n",
    "    sensor_data = simulator.run_simulation(\n",
    "        maze=maze,\n",
    "        agent_pos=current_pos,\n",
    "        source_pos=source_pos,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Compute spectrogram\n",
    "    spectrogram = simulator.compute_spectrogram(sensor_data)\n",
    "    spectrograms_history.append(spectrogram)\n",
    "    \n",
    "    # Normalize using training statistics\n",
    "    spectrogram_normalized = (spectrogram - normalization['mean']) / normalization['std']\n",
    "    \n",
    "    # Predict action\n",
    "    with torch.no_grad():\n",
    "        spec_tensor = torch.from_numpy(spectrogram_normalized).unsqueeze(0).to(device)\n",
    "        action_logits = model(spec_tensor)\n",
    "        action_probs = torch.softmax(action_logits, dim=1)\n",
    "        predicted_action = torch.argmax(action_logits, dim=1).item()\n",
    "    \n",
    "    # Get optimal action for comparison\n",
    "    optimal_action = oracle.get_optimal_action(current_pos, goal_pos)\n",
    "    \n",
    "    print(f\"  Predicted action: {action_names[predicted_action]}\")\n",
    "    print(f\"  Optimal action: {action_names[optimal_action]}\")\n",
    "    print(f\"  Action probabilities: {action_probs[0].cpu().numpy()}\")\n",
    "    \n",
    "    # Take action\n",
    "    actions_taken.append(predicted_action)\n",
    "    delta = action_deltas[Action(predicted_action)]\n",
    "    next_pos = (current_pos[0] + delta[0], current_pos[1] + delta[1])\n",
    "    \n",
    "    # Check if move is valid\n",
    "    if (\n",
    "        0 <= next_pos[0] < maze.shape[0] and\n",
    "        0 <= next_pos[1] < maze.shape[1] and\n",
    "        maze[next_pos[0], next_pos[1]] == 0\n",
    "    ):\n",
    "        current_pos = next_pos\n",
    "        trajectory.append(current_pos)\n",
    "        print(f\"  → Moved to: {current_pos}\")\n",
    "    else:\n",
    "        print(f\"  × Invalid move! Staying at: {current_pos}\")\n",
    "        trajectory.append(current_pos)  # Stay in place\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Final status\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if reached_goal:\n",
    "    print(\"✓ NAVIGATION SUCCESSFUL!\")\n",
    "    print(f\"  Steps taken: {len(trajectory)}\")\n",
    "    print(f\"  Optimal steps: {len(optimal_path)}\")\n",
    "    print(f\"  Efficiency: {100 * len(optimal_path) / len(trajectory):.1f}%\")\n",
    "else:\n",
    "    print(\"× Navigation failed (max steps reached)\")\n",
    "    print(f\"  Steps taken: {len(trajectory)}\")\n",
    "    print(f\"  Distance to goal: {oracle._heuristic(current_pos, goal_pos):.1f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Navigation Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot complete trajectory\n",
    "fig = plot_navigation_episode(\n",
    "    maze=maze,\n",
    "    trajectory=trajectory,\n",
    "    goal_pos=goal_pos,\n",
    "    actions=actions_taken,\n",
    "    title=\"Agent Navigation Using Acoustic Perception\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Plot comparison with optimal path\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Optimal path\n",
    "plot_maze(\n",
    "    maze,\n",
    "    agent_pos=start_pos,\n",
    "    goal_pos=goal_pos,\n",
    "    path=optimal_path,\n",
    "    title=f\"Optimal Path (A*): {len(optimal_path)} steps\",\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "# Agent path\n",
    "plot_maze(\n",
    "    maze,\n",
    "    agent_pos=start_pos,\n",
    "    goal_pos=goal_pos,\n",
    "    path=trajectory,\n",
    "    title=f\"Agent Path (Acoustic): {len(trajectory)} steps\",\n",
    "    ax=ax2\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Action Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predicted vs optimal actions\n",
    "optimal_actions_for_trajectory = []\n",
    "for pos in trajectory[:-1]:  # Exclude final position\n",
    "    optimal_actions_for_trajectory.append(\n",
    "        oracle.get_optimal_action(pos, goal_pos)\n",
    "    )\n",
    "\n",
    "# Compute accuracy\n",
    "actions_array = np.array(actions_taken)\n",
    "optimal_array = np.array(optimal_actions_for_trajectory)\n",
    "action_accuracy = 100 * (actions_array == optimal_array).sum() / len(actions_array)\n",
    "\n",
    "print(f\"Action Prediction Analysis:\")\n",
    "print(f\"  Total actions: {len(actions_taken)}\")\n",
    "print(f\"  Correct actions: {(actions_array == optimal_array).sum()}\")\n",
    "print(f\"  Accuracy: {action_accuracy:.2f}%\")\n",
    "\n",
    "# Action distribution\n",
    "print(f\"\\nAction Distribution:\")\n",
    "for action_idx, action_name in enumerate(action_names):\n",
    "    count = (actions_array == action_idx).sum()\n",
    "    print(f\"  {action_name}: {count} ({100*count/len(actions_array):.1f}%)\")\n",
    "\n",
    "# Plot action comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "x = np.arange(len(actions_taken))\n",
    "ax.plot(x, actions_taken, 'o-', label='Predicted', linewidth=2, markersize=6)\n",
    "ax.plot(x, optimal_actions_for_trajectory, 's--', label='Optimal', linewidth=2, markersize=6, alpha=0.7)\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Action')\n",
    "ax.set_yticks(range(5))\n",
    "ax.set_yticklabels(action_names)\n",
    "ax.set_title('Action Predictions vs Optimal Actions')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Sample Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show spectrograms from first few steps\n",
    "num_samples = min(3, len(spectrograms_history))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    print(f\"\\nStep {i+1}:\")\n",
    "    print(f\"  Position: {trajectory[i]}\")\n",
    "    print(f\"  Action: {action_names[actions_taken[i]]}\")\n",
    "    \n",
    "    fig = plot_multi_channel_spectrogram(\n",
    "        spectrograms_history[i],\n",
    "        title=f\"Step {i+1} Spectrogram (Position: {trajectory[i]}, Action: {action_names[actions_taken[i]]})\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "if reached_goal:\n",
    "    path_efficiency = 100 * len(optimal_path) / len(trajectory)\n",
    "    extra_steps = len(trajectory) - len(optimal_path)\n",
    "else:\n",
    "    path_efficiency = 0.0\n",
    "    extra_steps = float('inf')\n",
    "    final_distance = oracle._heuristic(current_pos, goal_pos)\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NAVIGATION PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nEnvironment:\")\n",
    "print(f\"  Maze size: {MAZE_WIDTH}×{MAZE_HEIGHT}\")\n",
    "print(f\"  Start: {start_pos}\")\n",
    "print(f\"  Goal: {goal_pos}\")\n",
    "print(f\"  Optimal path length: {len(optimal_path)} steps\")\n",
    "\n",
    "print(f\"\\nAgent Performance:\")\n",
    "print(f\"  Goal reached: {'✓ Yes' if reached_goal else '× No'}\")\n",
    "print(f\"  Steps taken: {len(trajectory)}\")\n",
    "if reached_goal:\n",
    "    print(f\"  Extra steps: {extra_steps}\")\n",
    "    print(f\"  Path efficiency: {path_efficiency:.1f}%\")\n",
    "else:\n",
    "    print(f\"  Final distance to goal: {final_distance:.1f}\")\n",
    "print(f\"  Action accuracy: {action_accuracy:.1f}%\")\n",
    "\n",
    "print(f\"\\nModel Information:\")\n",
    "print(f\"  Training accuracy: {performance['final_val_accuracy']:.2f}%\")\n",
    "print(f\"  Best epoch: {performance['best_epoch']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Optional: Create Animation Frames\n",
    "\n",
    "Generate individual frames that can be combined into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to create animation frames\n",
    "# create_animation_frames(\n",
    "#     maze=maze,\n",
    "#     trajectory=trajectory,\n",
    "#     goal_pos=goal_pos,\n",
    "#     output_dir='../data/animation_frames',\n",
    "#     figsize=(8, 8)\n",
    "# )\n",
    "# \n",
    "# print(\"\\n✓ Animation frames created!\")\n",
    "# print(\"To create video, run:\")\n",
    "# print(\"  ffmpeg -framerate 5 -i ../data/animation_frames/frame_%04d.png -c:v libx264 -pix_fmt yuv420p navigation.mp4\")\n",
    "\n",
    "print(\"\\n✓ Demo complete!\")\n",
    "print(\"\\nExperiment with:\")\n",
    "print(\"  - Different maze configurations\")\n",
    "print(\"  - Various start/goal positions\")\n",
    "print(\"  - Modified acoustic parameters\")\n",
    "print(\"  - Alternative model architectures (AudioNavResNet)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
