{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Navigation Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.1+cu126\n",
      "built with CUDA: 12.6\n",
      "cuda available: True\n",
      "cuda built: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"built with CUDA:\", torch.version.cuda)        # None => CPU-only build\n",
    "print(\"cuda available:\", torch.cuda.is_available())  # should be True\n",
    "print(\"cuda built:\", torch.backends.cuda.is_built()) # True if GPU build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu126\n",
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ab3b0c00f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.cave_dataset import (\n",
    "    MultiCaveDataset,\n",
    "    ACTION_MAP,\n",
    "    ACTION_NAMES,\n",
    "    MIC_OFFSETS,\n",
    "    compute_class_distribution,\n",
    "    compute_class_weights,\n",
    ")\n",
    "from src.models import CompactAcousticNet, SpatialTemporalAcousticNet, FocalLoss\n",
    "from src.lmdb_dataset import LMDBAcousticDataset\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danyi\\repo\\Audio-Maze-Navigation\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.5)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LMDB dataset: 96,868 samples\n",
      "Action distribution: {'stop': 100, 'up': 48697, 'down': 43300, 'left': 2318, 'right': 2453}\n",
      "Scanning dataset to group indices by class...\n",
      "\n",
      "Class Counts Found: {2: 43300, 4: 2453, 3: 2318, 1: 48697}\n",
      "--> Downsampling all classes to match the smallest: 2318 samples each\n",
      "\n",
      "✅ Data Ready:\n",
      "  Train: 7417 samples\n",
      "  Val:   1855 samples\n"
     ]
    }
   ],
   "source": [
    "# Cell 4+5: Perfectly Balanced Dataset (Dynamic Downsampling)\n",
    "# ---------------------------------------------------------\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "# Import your specific dataset class\n",
    "from src.lmdb_dataset import LMDBAcousticDataset \n",
    "\n",
    "# 1. Load Raw Data\n",
    "# UPDATE PATH IF NEEDED\n",
    "DATASET_DIR = Path('D:/audiomaze_dataset_100')\n",
    "raw_dataset = LMDBAcousticDataset('D:/audiomaze_lmdb_100')\n",
    "\n",
    "# 2. Scan and Sort Indices by Class\n",
    "print(\"Scanning dataset to group indices by class...\")\n",
    "indices_by_class = defaultdict(list)\n",
    "\n",
    "# Iterate through dataset to sort indices (Fast with LMDB)\n",
    "for idx in range(len(raw_dataset)):\n",
    "    _, action, _, _ = raw_dataset[idx]\n",
    "    act = int(action)\n",
    "    # We only care about 1=UP, 2=DOWN, 3=LEFT, 4=RIGHT\n",
    "    if act in [1, 2, 3, 4]:\n",
    "        indices_by_class[act].append(idx)\n",
    "\n",
    "# 3. Find the LIMIT (The count of the smallest class)\n",
    "# This will automatically be ~2300 or ~2500 based on your data\n",
    "min_count = min(len(indices_by_class[c]) for c in [1, 2, 3, 4])\n",
    "print(f\"\\nClass Counts Found: { {k: len(v) for k,v in indices_by_class.items()} }\")\n",
    "print(f\"--> Downsampling all classes to match the smallest: {min_count} samples each\")\n",
    "\n",
    "# 4. Create Perfectly Balanced Index List\n",
    "balanced_indices = []\n",
    "for cls in [1, 2, 3, 4]:\n",
    "    # Randomly sample 'min_count' indices from this class\n",
    "    # This ensures we use the MAXIMUM possible amount of data while staying balanced\n",
    "    sampled = random.sample(indices_by_class[cls], min_count)\n",
    "    balanced_indices.extend(sampled)\n",
    "\n",
    "# Shuffle to mix classes\n",
    "random.shuffle(balanced_indices)\n",
    "\n",
    "# 5. Create Dataset & Split\n",
    "balanced_dataset = Subset(raw_dataset, balanced_indices)\n",
    "\n",
    "# Get targets for stratify split\n",
    "balanced_targets = []\n",
    "for i in balanced_indices:\n",
    "    # Quick fetch of just the label\n",
    "    _, action, _, _ = raw_dataset[i]\n",
    "    balanced_targets.append(int(action))\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(balanced_dataset)), \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=balanced_targets\n",
    ")\n",
    "\n",
    "train_dataset = Subset(balanced_dataset, train_idx)\n",
    "val_dataset = Subset(balanced_dataset, val_idx)\n",
    "\n",
    "# 6. Loaders\n",
    "# We can use a standard loader now because the underlying data is already balanced\n",
    "BATCH_SIZE = 256 \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\n✅ Data Ready:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val:   {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SpatialTemporalAcousticNet\n",
      "Total parameters: 1,268,901\n",
      "Using FocalLoss (gamma=2.0) to handle class hardness\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Model & Focal Loss\n",
    "# ---------------------------------------------------------\n",
    "import torch.nn as nn\n",
    "from src.models import CompactAcousticNet, SpatialTemporalAcousticNet, FocalLoss\n",
    "\n",
    "MODEL_TYPE = 'spatial'\n",
    "NUM_CLASSES = 5  # Back to 5 classes (0=STOP included)\n",
    "\n",
    "if MODEL_TYPE == 'compact':\n",
    "    model = CompactAcousticNet(num_classes=NUM_CLASSES, dropout=0.3).to(device)\n",
    "    print('Using CompactAcousticNet')\n",
    "else:\n",
    "    model = SpatialTemporalAcousticNet(num_classes=NUM_CLASSES, dropout=0.3).to(device)\n",
    "    print('Using SpatialTemporalAcousticNet')\n",
    "\n",
    "# OPTIONAL: Load weights if you want to continue training\n",
    "# model.load_state_dict(torch.load(\"checkpoints/best_model.pt\")['model_state'])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "\n",
    "# Use Focal Loss to further penalize ignoring rare classes\n",
    "# alpha can be set to class weights, but the Sampler already handles balance.\n",
    "# We use gamma=2.0 to focus on \"hard\" examples.\n",
    "criterion = FocalLoss(gamma=2.0, reduction='mean') \n",
    "print('Using FocalLoss (gamma=2.0) to handle class hardness')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ WavefrontNet (2D CNN) Loaded.\n",
      "   Treats audio as an 8-row image to detect phase slopes.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Model Architecture (WideFieldNet)\n",
    "# ---------------------------------------------------------\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class WideFieldNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Wide-Field Acoustic Network.\n",
    "    Designed for Reverberant Environments:\n",
    "    1. Large Kernel (64) in Layer 1 to capture long-range Impulse Response (Echoes).\n",
    "    2. Stride 2 to preserve phase cues better than MaxPool.\n",
    "    3. LeakyReLU to prevent dead gradients during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=4, in_channels=8, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            # Layer 1: The \"Echo Catcher\" (64 samples ~= 0.4ms)\n",
    "            nn.Conv1d(in_channels, 64, kernel_size=64, stride=2, padding=31),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            # Layer 2: Texture & Decay\n",
    "            nn.Conv1d(64, 128, kernel_size=32, stride=2, padding=15),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            # Layer 3: Deep Features\n",
    "            nn.Conv1d(128, 256, kernel_size=16, stride=2, padding=7),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            # Layer 4: Global Context\n",
    "            nn.Conv1d(256, 512, kernel_size=8, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.AdaptiveAvgPool1d(1), # Squeeze time to 1 vector\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.encoder(x))\n",
    "\n",
    "# Instantiate\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = WideFieldNet(num_classes=4, dropout=0.5).to(device)\n",
    "\n",
    "# Standard AdamW is stable for this architecture\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "print(\"✅ WideFieldNet Loaded (Final Architecture).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING 2D WAVEFRONT TRAINING\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb81119e7e84049b7aee46834ec389f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 1/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.250 | Preds: 0:32% | 1:27% | 2:23% | 3:19%\n",
      "  --> Saved Best Model\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a3faae6c5c4098bd73e39313ff6033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 2/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.258 | Preds: 0:30% | 1:22% | 2:23% | 3:25%\n",
      "  --> Saved Best Model\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec6f69416824898b6d33200887a2eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 3/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.250 | Preds: 0:28% | 1:23% | 2:23% | 3:26%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7319ea57d0474203bf9c81a5d06118de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 4/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.250 | Preds: 0:25% | 1:24% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51936f8a379b4288ba54a774e1f99016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 5/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.252 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee542a39f24741babde151c97d37b287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 6/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.250 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7608cd97e4343a685880f65bd888500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 7/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.250 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a25b5a634bd4200b10ddecf4d532a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 8/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.343 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "  --> Saved Best Model\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee44116dd9d84811aebc179052d96f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 9/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.253 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc232ffcc5043dc8a14ac46689d276d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 10/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.291 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca1a64f6f564c2886b3ab0776e9bb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 11/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.351 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "  --> Saved Best Model\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dc86b95064478bb35aae8e649d5c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 12/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.292 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f4cb534941449eb519431a40a9acb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 13/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.356 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "  --> Saved Best Model\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215dc3111ee44f4b9c9be7086964208d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 14/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.319 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ab2a94dda4442eb4ed2a9e13d9d0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 15/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Val Acc: 0.340 | Preds: 0:25% | 1:25% | 2:25% | 3:25%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f2fa69023c498f872af3a3a1f4a21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ep 16/20:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: WavefrontNet Training\n",
    "# ---------------------------------------------------------\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# Config\n",
    "EPOCHS = 20\n",
    "LR = 0.001\n",
    "save_dir = Path(\"checkpoints\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else torch.amp.GradScaler(enabled=False)\n",
    "autocast_ctx = lambda: torch.amp.autocast('cuda') if torch.cuda.is_available() else nullcontext()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"STARTING 2D WAVEFRONT TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    pred_counts = {0:0, 1:0, 2:0, 3:0}\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Ep {epoch+1}/{EPOCHS}\", dynamic_ncols=True, colour=\"#4CAF50\")\n",
    "    for mic, action, _, _ in pbar:\n",
    "        mic = mic.to(device, non_blocking=True)\n",
    "        action = action.to(device, non_blocking=True)\n",
    "        targets = action - 1 \n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast_ctx():\n",
    "            logits = model(mic)\n",
    "            loss = criterion(logits, targets)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        train_correct += (preds == targets).sum().item()\n",
    "        train_total += targets.numel()\n",
    "        \n",
    "        for p in preds.tolist(): pred_counts[p] += 1\n",
    "            \n",
    "        pbar.set_postfix(acc=train_correct/train_total)\n",
    "\n",
    "    # --- VALIDATION ---\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for mic, action, _, _ in val_loader:\n",
    "            mic = mic.to(device, non_blocking=True)\n",
    "            action = action.to(device, non_blocking=True)\n",
    "            targets = action - 1\n",
    "\n",
    "            with autocast_ctx():\n",
    "                logits = model(mic)\n",
    "            \n",
    "            preds = logits.argmax(dim=1)\n",
    "            val_correct += (preds == targets).sum().item()\n",
    "            val_total += targets.numel()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_targets.extend(targets.cpu().tolist())\n",
    "\n",
    "    avg_val_acc = val_correct / val_total\n",
    "    scheduler.step(avg_val_acc)\n",
    "    \n",
    "    total_preds = sum(pred_counts.values())\n",
    "    dist_str = \" | \".join([f\"{k}:{v/total_preds:.0%}\" for k,v in pred_counts.items()])\n",
    "    print(f\"\\n  Val Acc: {avg_val_acc:.3f} | Preds: {dist_str}\")\n",
    "    \n",
    "    if avg_val_acc > best_val_acc:\n",
    "        best_val_acc = avg_val_acc\n",
    "        torch.save(model.state_dict(), \"best_model_2d.pt\")\n",
    "        print(\"  --> Saved Best Model\")\n",
    "    \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DIAGNOSTICS REPORT ---\n",
      "Input Shape: torch.Size([256, 8, 11434])\n",
      "Input Stats: Mean=-0.0000 | Std=1.0000\n",
      "             Min=-15.4346  | Max=16.2569\n",
      "\n",
      "Model Predictions (First 5 samples):\n",
      "   UP      DOWN    LEFT    RIGHT\n",
      "  [0.1222, 0.5740, 0.0076, 0.2962]\n",
      "  [0.0634, 0.6904, 0.0100, 0.2362]\n",
      "  [0.0793, 0.6417, 0.0235, 0.2555]\n",
      "  [0.1160, 0.5552, 0.0177, 0.3110]\n",
      "  [0.1123, 0.5922, 0.0073, 0.2882]\n",
      "\n",
      "Gradient Health (Layer-wise norms):\n",
      "\n",
      "Gradients look healthy. The architecture just needs to be smarter.\n"
     ]
    }
   ],
   "source": [
    "# Cell: Deep Diagnostics (Inputs, Outputs, Gradients)\n",
    "# ---------------------------------------------------------\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- DIAGNOSTICS REPORT ---\")\n",
    "\n",
    "# 1. Check Input Statistics (Is data normalized?)\n",
    "# ---------------------------------------------------------\n",
    "batch = next(iter(train_loader))\n",
    "mics, acts, _, _ = batch\n",
    "mics = mics.to(device)\n",
    "print(f\"Input Shape: {mics.shape}\")\n",
    "print(f\"Input Stats: Mean={mics.mean():.4f} | Std={mics.std():.4f}\")\n",
    "print(f\"             Min={mics.min():.4f}  | Max={mics.max():.4f}\")\n",
    "\n",
    "if mics.std() < 0.1:\n",
    "    print(\"⚠️ WARNING: Inputs are very quiet. Model might struggle to find signal.\")\n",
    "\n",
    "# 2. Check Model Confidence (Is it guessing blindly or confidently wrong?)\n",
    "# ---------------------------------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(mics)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "print(\"\\nModel Predictions (First 5 samples):\")\n",
    "print(\"   UP      DOWN    LEFT    RIGHT\")\n",
    "for p in probs[:5]:\n",
    "    print(f\"  [{p[0]:.4f}, {p[1]:.4f}, {p[2]:.4f}, {p[3]:.4f}]\")\n",
    "\n",
    "# 3. Check Gradients (Is the model learning or dead?)\n",
    "# ---------------------------------------------------------\n",
    "model.train()\n",
    "model.zero_grad()\n",
    "# Forward pass again for grads\n",
    "logits = model(mics)\n",
    "targets = (acts - 1).to(device)\n",
    "loss = torch.nn.CrossEntropyLoss()(logits, targets)\n",
    "loss.backward()\n",
    "\n",
    "print(\"\\nGradient Health (Layer-wise norms):\")\n",
    "dead_layers = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None and param.dim() > 1: # Only weights, ignore biases\n",
    "        grad_norm = param.grad.norm().item()\n",
    "        if grad_norm == 0.0:\n",
    "            print(f\"  ❌ DEAD (0.0): {name}\")\n",
    "            dead_layers += 1\n",
    "        elif grad_norm > 10.0:\n",
    "            print(f\"  ⚠️ EXPLODING ({grad_norm:.2f}): {name}\")\n",
    "        else:\n",
    "            # Print first layer only to save space\n",
    "            if \"front_end.0\" in name:\n",
    "                 print(f\"  ✅ OK ({grad_norm:.4f}): {name}\")\n",
    "\n",
    "if dead_layers > 0:\n",
    "    print(f\"\\nCRITICAL: {dead_layers} layers have zero gradient. Use LeakyReLU or check initialization.\")\n",
    "else:\n",
    "    print(\"\\nGradients look healthy. The architecture just needs to be smarter.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
