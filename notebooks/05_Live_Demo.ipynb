{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Navigation Demo\n",
    "\n",
    "Interactive demonstration of trained acoustic navigation agent.\n",
    "\n",
    "## Features:\n",
    "- Generate a new test cave\n",
    "- Load trained model\n",
    "- Simulate agent navigating using only acoustic signals\n",
    "- Live visualization of agent movement\n",
    "- Compare with optimal path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, clear_output\n",
    "import time\n",
    "\n",
    "from data.audio_cave import AudioCave\n",
    "from src.models import CompactAcousticNet, SpatialTemporalAcousticNet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Test Cave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new test cave (different from training)\n",
    "print(\"Generating test cave...\")\n",
    "cave = AudioCave(width=60, height=60, min_corridor_width=3, wall_thickness_range=(1, 8))\n",
    "\n",
    "print(f\"Cave size: {cave.height}x{cave.width}\")\n",
    "print(f\"Start: {cave.start}\")\n",
    "print(f\"Goal: {cave.end}\")\n",
    "print(f\"Walls: {100*cave.grid.mean():.1f}%\")\n",
    "print(f\"Air: {100*(1-cave.grid.mean()):.1f}%\")\n",
    "\n",
    "cave.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model checkpoint\n",
    "CHECKPOINT_PATH = Path('../notebooks/checkpoints/best_model.pt')\n",
    "\n",
    "if not CHECKPOINT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\\nTrain a model first using 03_Training.ipynb\")\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "\n",
    "print(\"Checkpoint Info:\")\n",
    "print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  Val Accuracy: {checkpoint.get('val_acc', 0):.4f}\")\n",
    "\n",
    "# Create model (match architecture used in training)\n",
    "MODEL_TYPE = 'compact'  # Change to 'spatial_temporal' if you trained that model\n",
    "ACTION_NAMES = ['STOP', 'UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "\n",
    "if MODEL_TYPE == 'compact':\n",
    "    model = CompactAcousticNet(num_classes=5, dropout=0.3).to(device)\n",
    "    print(\"Using CompactAcousticNet\")\n",
    "else:\n",
    "    model = SpatialTemporalAcousticNet(num_classes=5, dropout=0.3).to(device)\n",
    "    print(\"Using SpatialTemporalAcousticNet\")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n✓ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simulate Acoustic Navigation\n",
    "\n",
    "**Note:** This is a simplified simulation without actual k-Wave acoustic propagation.\n",
    "In reality, you would:\n",
    "1. Run k-Wave simulation at each position\n",
    "2. Capture 8-mic pressure data\n",
    "3. Feed to model for action prediction\n",
    "\n",
    "For this demo, we'll use a mock sensor that reads pre-simulated data or random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock acoustic sensor (replace with real k-Wave simulation)\n",
    "def mock_acoustic_sensor(position, cave_grid, timesteps=11434):\n",
    "    \"\"\"\n",
    "    Mock sensor that generates pseudo-acoustic data.\n",
    "    In real demo, this would run k-Wave simulation.\n",
    "    \"\"\"\n",
    "    # Generate random acoustic-like signal (8 mics)\n",
    "    # In reality: run k-Wave simulation at this position\n",
    "    mic_data = np.random.randn(8, timesteps).astype(np.float32) * 0.003\n",
    "    \n",
    "    # Add position-dependent features (mock spatial info)\n",
    "    y, x = position\n",
    "    spatial_bias = np.sin(y * 0.1) * np.cos(x * 0.1)\n",
    "    mic_data += spatial_bias * 0.001\n",
    "    \n",
    "    return mic_data\n",
    "\n",
    "print(\"Mock sensor ready (replace with real k-Wave for production)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action mappings\n",
    "action_to_delta = {\n",
    "    0: (0, 0),   # STOP\n",
    "    1: (-1, 0),  # UP\n",
    "    2: (1, 0),   # DOWN\n",
    "    3: (0, -1),  # LEFT\n",
    "    4: (0, 1),   # RIGHT\n",
    "}\n",
    "\n",
    "def is_valid_move(position, cave_grid, agent_radius=1):\n",
    "    \"\"\"Check if position has valid 3x3 footprint.\"\"\"\n",
    "    y, x = position\n",
    "    if y - agent_radius < 0 or y + agent_radius >= cave_grid.shape[0]:\n",
    "        return False\n",
    "    if x - agent_radius < 0 or x + agent_radius >= cave_grid.shape[1]:\n",
    "        return False\n",
    "    footprint = cave_grid[y - agent_radius:y + agent_radius + 1, x - agent_radius:x + agent_radius + 1]\n",
    "    return np.all(footprint == 0)\n",
    "\n",
    "def predict_action(model, mic_data, device):\n",
    "    \"\"\"Predict action from mic data.\"\"\"\n",
    "    # Normalize per-sample\n",
    "    mic_mean = mic_data.mean()\n",
    "    mic_std = mic_data.std()\n",
    "    if mic_std > 1e-8:\n",
    "        mic_data_norm = (mic_data - mic_mean) / mic_std\n",
    "    else:\n",
    "        mic_data_norm = mic_data - mic_mean\n",
    "    \n",
    "    # Convert to tensor\n",
    "    mic_tensor = torch.from_numpy(mic_data_norm).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = model(mic_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        action = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    return action, probs[0].cpu().numpy()\n",
    "\n",
    "print(\"Navigation functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Navigation Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigation parameters\n",
    "MAX_STEPS = 100\n",
    "current_pos = cave.start\n",
    "goal_pos = cave.end\n",
    "\n",
    "# Track trajectory\n",
    "trajectory = [current_pos]\n",
    "actions_taken = []\n",
    "action_probs_history = []\n",
    "\n",
    "print(f\"Starting navigation from {current_pos} to {goal_pos}\")\n",
    "print(f\"Optimal path length: {len([p for row in cave.action_grid for p in row if p != ''])}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Navigation loop\n",
    "for step in range(MAX_STEPS):\n",
    "    # Check if reached goal\n",
    "    if current_pos == goal_pos:\n",
    "        print(f\"\\n✓ GOAL REACHED in {step} steps!\")\n",
    "        break\n",
    "    \n",
    "    # Get acoustic data (mock)\n",
    "    mic_data = mock_acoustic_sensor(current_pos, cave.grid)\n",
    "    \n",
    "    # Predict action\n",
    "    action, probs = predict_action(model, mic_data, device)\n",
    "    \n",
    "    # Get optimal action for comparison\n",
    "    optimal_action = cave.action_grid[current_pos[0]][current_pos[1]]\n",
    "    action_map_inv = {'stop': 0, 'up': 1, 'down': 2, 'left': 3, 'right': 4}\n",
    "    optimal_action_idx = action_map_inv.get(optimal_action, 0)\n",
    "    \n",
    "    # Execute action\n",
    "    delta = action_to_delta[action]\n",
    "    next_pos = (current_pos[0] + delta[0], current_pos[1] + delta[1])\n",
    "    \n",
    "    # Validate move\n",
    "    if is_valid_move(next_pos, cave.grid):\n",
    "        current_pos = next_pos\n",
    "        move_status = \"✓\"\n",
    "    else:\n",
    "        move_status = \"✗ (invalid)\"\n",
    "    \n",
    "    # Record\n",
    "    trajectory.append(current_pos)\n",
    "    actions_taken.append(action)\n",
    "    action_probs_history.append(probs)\n",
    "    \n",
    "    # Progress update every 10 steps\n",
    "    if (step + 1) % 10 == 0:\n",
    "        dist = np.linalg.norm(np.array(current_pos) - np.array(goal_pos))\n",
    "        print(f\"Step {step+1}: pos={current_pos}, action={ACTION_NAMES[action]} (optimal={optimal_action}), dist={dist:.1f} {move_status}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n✗ Max steps reached ({MAX_STEPS})\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Final position: {current_pos}\")\n",
    "print(f\"Total steps: {len(trajectory)}\")\n",
    "print(f\"Actions taken: {len(actions_taken)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left: Cave with trajectory\n",
    "ax1.imshow(cave.grid.T, origin='lower', cmap='binary')\n",
    "ax1.scatter([cave.start[0]], [cave.start[1]], s=300, c='green', marker='o', \n",
    "           edgecolors='black', linewidths=2, label='Start', zorder=10)\n",
    "ax1.scatter([cave.end[0]], [cave.end[1]], s=300, c='red', marker='*', \n",
    "           edgecolors='black', linewidths=2, label='Goal', zorder=10)\n",
    "\n",
    "# Plot trajectory\n",
    "if len(trajectory) > 1:\n",
    "    traj_array = np.array(trajectory)\n",
    "    ax1.plot(traj_array[:, 0], traj_array[:, 1], 'b-', linewidth=2, alpha=0.7, label='Agent Path')\n",
    "    ax1.scatter(traj_array[:, 0], traj_array[:, 1], c=range(len(trajectory)), \n",
    "               cmap='coolwarm', s=50, zorder=5, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "ax1.set_title(f'Agent Navigation ({len(trajectory)} steps)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.legend()\n",
    "ax1.axis('image')\n",
    "\n",
    "# Right: Optimal path comparison\n",
    "symbol_map = {\"up\": 1, \"down\": 2, \"left\": 3, \"right\": 4, \"stop\": 5, \"\": 0}\n",
    "action_numeric = np.vectorize(symbol_map.get)(cave.action_grid)\n",
    "ax2.imshow(action_numeric.T, origin='lower', cmap='tab10', vmin=0, vmax=5, alpha=0.6)\n",
    "ax2.contour(cave.grid.T, levels=[0.5], colors='black', linewidths=1)\n",
    "ax2.scatter([cave.start[0]], [cave.start[1]], s=300, c='green', marker='o', \n",
    "           edgecolors='black', linewidths=2, label='Start', zorder=10)\n",
    "ax2.scatter([cave.end[0]], [cave.end[1]], s=300, c='red', marker='*', \n",
    "           edgecolors='black', linewidths=2, label='Goal', zorder=10)\n",
    "ax2.set_title('Optimal Action Field (BFS)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.legend()\n",
    "ax2.axis('image')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Action Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute action accuracy\n",
    "action_map_inv = {'stop': 0, 'up': 1, 'down': 2, 'left': 3, 'right': 4, '': 0}\n",
    "optimal_actions = []\n",
    "for pos in trajectory[:-1]:\n",
    "    opt_act = cave.action_grid[pos[0]][pos[1]]\n",
    "    optimal_actions.append(action_map_inv.get(opt_act, 0))\n",
    "\n",
    "actions_array = np.array(actions_taken)\n",
    "optimal_array = np.array(optimal_actions)\n",
    "\n",
    "if len(actions_array) > 0 and len(optimal_array) > 0:\n",
    "    matches = (actions_array == optimal_array).sum()\n",
    "    accuracy = 100 * matches / len(actions_array)\n",
    "    print(f\"Action Accuracy: {accuracy:.1f}% ({matches}/{len(actions_array)})\")\n",
    "    \n",
    "    # Action distribution\n",
    "    print(\"\\nAction Distribution:\")\n",
    "    for i, name in enumerate(ACTION_NAMES):\n",
    "        count = (actions_array == i).sum()\n",
    "        print(f\"  {name}: {count} ({100*count/len(actions_array):.1f}%)\")\n",
    "else:\n",
    "    print(\"No actions taken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot action probabilities over time\n",
    "if len(action_probs_history) > 0:\n",
    "    probs_array = np.array(action_probs_history)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    for i, name in enumerate(ACTION_NAMES):\n",
    "        ax.plot(probs_array[:, i], label=name, linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Step', fontsize=12)\n",
    "    ax.set_ylabel('Action Probability', fontsize=12)\n",
    "    ax.set_title('Model Confidence Over Time', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "reached_goal = (trajectory[-1] == goal_pos)\n",
    "path_length = len(trajectory)\n",
    "optimal_length = len([p for row in cave.action_grid for p in row if p != ''])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NAVIGATION PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nEnvironment:\")\n",
    "print(f\"  Cave size: {cave.height}x{cave.width}\")\n",
    "print(f\"  Start: {cave.start}\")\n",
    "print(f\"  Goal: {cave.end}\")\n",
    "print(f\"  Euclidean distance: {np.linalg.norm(np.array(cave.start) - np.array(cave.end)):.1f}\")\n",
    "\n",
    "print(f\"\\nAgent Performance:\")\n",
    "print(f\"  Goal reached: {'✓ YES' if reached_goal else '✗ NO'}\")\n",
    "print(f\"  Steps taken: {path_length}\")\n",
    "print(f\"  Max steps allowed: {MAX_STEPS}\")\n",
    "\n",
    "if len(actions_array) > 0 and len(optimal_array) > 0:\n",
    "    print(f\"  Action accuracy: {accuracy:.1f}%\")\n",
    "\n",
    "if reached_goal:\n",
    "    print(f\"  Path efficiency: {100 * optimal_length / path_length:.1f}%\")\n",
    "    print(f\"  Extra steps: {path_length - optimal_length}\")\n",
    "else:\n",
    "    final_dist = np.linalg.norm(np.array(trajectory[-1]) - np.array(goal_pos))\n",
    "    print(f\"  Final distance to goal: {final_dist:.1f}\")\n",
    "\n",
    "print(f\"\\nModel Info:\")\n",
    "print(f\"  Architecture: {MODEL_TYPE}\")\n",
    "print(f\"  Checkpoint epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  Validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  Validation accuracy: {checkpoint.get('val_acc', 0)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Try Different Test Cases\n",
    "\n",
    "Re-run cells from section 1 onwards to test on new caves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✓ Demo Complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Re-run from Section 1 to test on a new cave\")\n",
    "print(\"  2. Try different model architectures (change MODEL_TYPE)\")\n",
    "print(\"  3. Integrate real k-Wave simulation (replace mock_acoustic_sensor)\")\n",
    "print(\"  4. Experiment with larger/smaller caves\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
