{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Navigation - Model Training\n",
    "\n",
    "## Training Pipeline Overview\n",
    "\n",
    "**Task**: Predict optimal navigation action from acoustic sensor data\n",
    "\n",
    "### Agent Setup:\n",
    "- Agent occupies center of 3x3 grid cell\n",
    "- 8 microphones arranged in circle around agent (1 cell radius)\n",
    "- Each microphone records pressure time-series\n",
    "- **CRITICAL**: No part of 3x3 agent footprint can be inside walls!\n",
    "\n",
    "### Training Approach:\n",
    "1. Sample agent positions from navigable cave space (ensuring 3x3 validity)\n",
    "2. Extract 8-mic acoustic data at each position\n",
    "3. Predict action: STOP, UP, DOWN, LEFT, RIGHT\n",
    "4. Handle class imbalance (STOP is rarer than movement actions)\n",
    "\n",
    "### This Notebook:\n",
    "1. Load HDF5 dataset\n",
    "2. Create proper PyTorch DataLoader with 3x3 validation\n",
    "3. Visualize data distribution (action balance, agent positions)\n",
    "4. Show sample agent with 8-mic array\n",
    "5. Prepare for model training (next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (folder with many cave_*.h5 files)\n",
    "DATASET_DIR = Path('D:/audiomaze_dataset')\n",
    "H5_FILES = sorted(DATASET_DIR.glob('cave_*.h5'))\n",
    "assert len(H5_FILES) > 0, f\"No cave_*.h5 files found in {DATASET_DIR}\"\n",
    "\n",
    "# Agent configuration\n",
    "AGENT_RADIUS = 1\n",
    "\n",
    "# Import dataset utilities\n",
    "from src.cave_dataset import (\n",
    "    MultiCaveDataset,\n",
    "    ACTION_MAP,\n",
    "    ACTION_NAMES,\n",
    "    MIC_OFFSETS,\n",
    "    compute_class_distribution,\n",
    "    compute_class_weights,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(H5_FILES)} files in {DATASET_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first H5 file for visualization reference (file 0)\n",
    "viz_file = H5_FILES[0]\n",
    "with h5py.File(viz_file, 'r') as f:\n",
    "    first_key = list(f.keys())[0]\n",
    "    cave_grid = f[first_key]['cave_grid'][:]\n",
    "    action_grid_raw = f[first_key]['action_grid'][:]\n",
    "    if action_grid_raw.dtype.kind == 'S':\n",
    "        action_grid_str = np.vectorize(lambda x: x.decode('utf-8'))(action_grid_raw)\n",
    "    else:\n",
    "        action_grid_str = action_grid_raw.astype(str)\n",
    "    pressure_field = f[first_key]['pressure_timeseries'][:]\n",
    "    end_pos = tuple(f[first_key].attrs['end_position'])\n",
    "    start_pos = tuple(f[first_key].attrs.get('start_position', (-1, -1)))\n",
    "    dt = f[first_key].attrs['dt']\n",
    "    f0 = f[first_key].attrs['frequency_hz']\n",
    "\n",
    "Nx, Ny, Nt = pressure_field.shape\n",
    "\n",
    "print(f\"Loaded reference file: {viz_file}\")\n",
    "print(f\"Scene key: {first_key}\")\n",
    "print(f\"Grid size: {Nx}x{Ny}, Nt={Nt}\")\n",
    "print(f\"Start: {start_pos}, Goal: {end_pos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create PyTorch Dataset\n",
    "\n",
    "**Key Logic**:\n",
    "- Agent at (y, x) occupies 3x3 square centered at (y, x)\n",
    "- Extract 8-mic pressure time-series from surrounding cells\n",
    "- Label = action at center position\n",
    "- With 3x3 expansion system, actions only exist at valid centers (every 3rd cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multi-file dataset\n",
    "# Note: MultiCaveDataset handles valid-position filtering (3x3 footprint) per file\n",
    "\n",
    "dataset = MultiCaveDataset(H5_FILES, agent_radius=AGENT_RADIUS, mic_offsets=MIC_OFFSETS, action_map=ACTION_MAP)\n",
    "print(f\"Total valid positions across all files: {len(dataset.valid_positions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Action Distribution\n",
    "\n",
    "**Important**: STOP will be rarer than movement actions (only at goal).  \n",
    "We'll need to handle class imbalance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get action distribution across all files\n",
    "action_dist = dataset.get_action_distribution()\n",
    "\n",
    "print(\"Action Distribution:\")\n",
    "print(\"=\"*50)\n",
    "total_samples = len(dataset)\n",
    "for action_name in ACTION_NAMES:\n",
    "    action_str = action_name.lower()\n",
    "    count = action_dist.get(action_str, 0)\n",
    "    percentage = 100 * count / total_samples\n",
    "    print(f\"  {action_name:>5s}: {count:>6d} ({percentage:>5.2f}%)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total samples (valid positions): {total_samples}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Valid Agent Positions\n",
    "\n",
    "Show where agents can be placed (3x3 expansion guarantees all are valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create valid position mask for the first file (viz only)\n",
    "viz_valid = np.zeros_like(cave_grid)\n",
    "for y, x in dataset.file_infos[0]['valid']:\n",
    "    viz_valid[y, x] = 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Cave layout\n",
    "axes[0].imshow(cave_grid, origin='upper', cmap='binary')\n",
    "axes[0].scatter([end_pos[1]], [end_pos[0]], s=200, c='red', marker='*',\n",
    "               edgecolors='black', linewidths=2, label='Goal', zorder=10)\n",
    "axes[0].set_title(f'Cave Layout ({Nx}x{Ny})', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Y')\n",
    "axes[0].legend()\n",
    "axes[0].axis('image')\n",
    "\n",
    "# Valid agent positions (first file)\n",
    "axes[1].imshow(viz_valid, origin='upper', cmap='Greens', alpha=0.6)\n",
    "axes[1].contour(cave_grid, levels=[0.5], colors='black', linewidths=1)\n",
    "axes[1].scatter([end_pos[1]], [end_pos[0]], s=200, c='red', marker='*',\n",
    "               edgecolors='black', linewidths=2, label='Goal', zorder=10)\n",
    "axes[1].set_title(f'Valid Agent Positions ({len(dataset.file_infos[0][\"valid\"])} total)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Y')\n",
    "axes[1].legend()\n",
    "axes[1].axis('image')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Valid agent positions (file 0): {len(dataset.file_infos[0]['valid'])} / {(Nx*Ny)} total cells\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Agent with 8-Mic Array\n",
    "\n",
    "Pick a random agent position and show:\n",
    "- 3x3 footprint\n",
    "- 8 microphone positions\n",
    "- Pressure time-series at each mic\n",
    "- Action label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random sample from the dataset\n",
    "sample_idx = np.random.randint(0, len(dataset))\n",
    "mic_data, action, (agent_y, agent_x), file_idx = dataset.get_sample_with_position(sample_idx)\n",
    "action_name = ACTION_NAMES[action.item()]\n",
    "\n",
    "print(f\"Sample {sample_idx} from file #{file_idx} ({dataset.file_infos[file_idx]['path'].name}):\")\n",
    "print(f\"  Agent position: ({agent_y}, {agent_x})\")\n",
    "print(f\"  Action: {action_name}\")\n",
    "print(f\"  Mic data shape: {mic_data.shape}\")\n",
    "print(f\"  Cave grid at agent: {dataset.file_infos[file_idx]['cave_grid'][agent_y, agent_x]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL MAP VISUALIZATION - Agent, Mics, and Goal (per sampled file)\n",
    "info = dataset.file_infos[file_idx]\n",
    "cg = info['cave_grid']\n",
    "ag = info['action_grid']\n",
    "end_local = info['end_pos']\n",
    "start_local = info['start_pos']\n",
    "Nx_local, Ny_local = cg.shape\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.imshow(cg, origin='upper', cmap='binary', alpha=0.8)\n",
    "ax.contour(cg, levels=[0.5], colors='gray', linewidths=1.5, alpha=0.5)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "r = AGENT_RADIUS\n",
    "rect = Rectangle((agent_x - r - 0.5, agent_y - r - 0.5), 2*r + 1, 2*r + 1,\n",
    "                linewidth=4, edgecolor='blue', facecolor='blue', alpha=0.3, label='3x3 Footprint')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "ax.scatter([agent_x], [agent_y], s=500, c='blue', marker='o',\n",
    "           edgecolors='white', linewidths=3, label='Agent', zorder=10)\n",
    "\n",
    "# Mic positions; only draw mics that are in air\n",
    "mic_ys = [agent_y + dy for dy, dx in MIC_OFFSETS]\n",
    "mic_xs = [agent_x + dx for dy, dx in MIC_OFFSETS]\n",
    "mic_in_air = [(mx, my) for mx, my in zip(mic_xs, mic_ys) if 0 <= my < Nx_local and 0 <= mx < Ny_local and cg[int(my), int(mx)] == 0]\n",
    "if mic_in_air:\n",
    "    ax.scatter([mx for mx,_ in mic_in_air], [my for _,my in mic_in_air], s=150, c='lime', marker='^',\n",
    "               edgecolors='black', linewidths=2, label='8 Microphones (air only)', zorder=9)\n",
    "\n",
    "ax.scatter([end_local[1]], [end_local[0]], s=400, c='red', marker='*',\n",
    "           edgecolors='black', linewidths=2, label='Goal (Sound Source)', zorder=8)\n",
    "\n",
    "ax.set_title(f'Full Cave Map - Agent at ({agent_y},{agent_x})\n",
    "Action: {action_name} (file {file_idx})',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Column Index', fontsize=12)\n",
    "ax.set_ylabel('Row Index', fontsize=12)\n",
    "ax.legend(loc='upper left', fontsize=10, framealpha=0.9)\n",
    "ax.axis('image')\n",
    "ax.grid(True, alpha=0.2, linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Right: Zoomed view around agent (same origin)\n",
    "ax = axes[1]\n",
    "zoom_radius = 10\n",
    "y_min = max(0, agent_y - zoom_radius)\n",
    "y_max = min(Nx_local, agent_y + zoom_radius + 1)\n",
    "x_min = max(0, agent_x - zoom_radius)\n",
    "x_max = min(Ny_local, agent_x + zoom_radius + 1)\n",
    "\n",
    "cave_zoom = cg[y_min:y_max, x_min:x_max]\n",
    "extent_zoom = [x_min - 0.5, x_max - 0.5, y_min - 0.5, y_max - 0.5]\n",
    "ax.imshow(cave_zoom, origin='upper', cmap='binary', alpha=0.8, extent=extent_zoom)\n",
    "\n",
    "rect_zoom = Rectangle((agent_x - r - 0.5, agent_y - r - 0.5), 2*r + 1, 2*r + 1,\n",
    "                      linewidth=4, edgecolor='blue', facecolor='blue', alpha=0.3)\n",
    "ax.add_patch(rect_zoom)\n",
    "\n",
    "if mic_in_air:\n",
    "    ax.scatter([mx for mx,_ in mic_in_air], [my for _,my in mic_in_air], s=150, c='lime', marker='^',\n",
    "               edgecolors='black', linewidths=2, label='Mics (air only)', zorder=9)\n",
    "\n",
    "mic_labels = ['R', 'DR', 'D', 'DL', 'L', 'UL', 'U', 'UR']\n",
    "for label, (mx, my) in zip(mic_labels, zip(mic_xs, mic_ys)):\n",
    "    if 0 <= my < Nx_local and 0 <= mx < Ny_local and cg[int(my), int(mx)] == 0:\n",
    "        ax.text(mx, my - 0.6, label, fontsize=9, fontweight='bold',\n",
    "                ha='center', va='top', color='darkgreen',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "ax.set_title(f'Zoomed View (\u00b1{zoom_radius} cells)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Column Index', fontsize=12)\n",
    "ax.set_ylabel('Row Index', fontsize=12)\n",
    "ax.legend(loc='upper left', fontsize=10, framealpha=0.9)\n",
    "ax.axis('image')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print summary\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"AGENT VERIFICATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Agent Position: ({agent_y}, {agent_x})\")\n",
    "print(f\"Cave grid at agent: {cg[agent_y, agent_x]} (0=air, 1=wall)\")\n",
    "print(f\"3x3 footprint all air: {np.all(cg[agent_y - r:agent_y + r + 1, agent_x - r:agent_x + r + 1] == 0)}\")\n",
    "print(f\"Action label: {action_name}\")\n",
    "print(f\"Goal Position: {end_local}\")\n",
    "print(f\"Distance to goal: {np.sqrt((agent_y-end_local[0])**2 + (agent_x-end_local[1])**2):.1f} cells\")\n",
    "print(f\"File: {info['path'].name}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow action labels from current agent position to goal (correct file)\n",
    "info = dataset.file_infos[file_idx]\n",
    "cg = info['cave_grid']\n",
    "ag = info['action_grid']\n",
    "end_local = info['end_pos']\n",
    "\n",
    "moves = {'up': (-1,0), 'down': (1,0), 'left': (0,-1), 'right': (0,1), 'stop': (0,0)}\n",
    "\n",
    "def follow_path(start_y, start_x, max_steps=2000):\n",
    "    path = [(int(start_y), int(start_x))]\n",
    "    r, c = start_y, start_x\n",
    "    for step in range(max_steps):\n",
    "        a = ag[r, c]\n",
    "        if isinstance(a, bytes):\n",
    "            a = a.decode('utf-8')\n",
    "        if a == 'stop':\n",
    "            return True, path\n",
    "        if a not in moves:\n",
    "            return False, path\n",
    "        dr, dc = moves[a]\n",
    "        nr, nc = r + dr, c + dc\n",
    "        if not (0 <= nr < cg.shape[0] and 0 <= nc < cg.shape[1]):\n",
    "            return False, path\n",
    "        if cg[nr, nc] == 1:\n",
    "            return False, path\n",
    "        r, c = nr, nc\n",
    "        path.append((int(r), int(c)))\n",
    "    return False, path\n",
    "\n",
    "ok, path = follow_path(agent_y, agent_x)\n",
    "print(f\"Path follow result: {'SUCCESS' if ok else 'FAIL'}, steps={len(path)-1}, end={path[-1]}, file={info['path'].name}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(cg, origin='upper', cmap='binary', alpha=0.8)\n",
    "ys = [p[0] for p in path]; xs = [p[1] for p in path]\n",
    "ax.plot(xs, ys, '-o', color='lime' if ok else 'red', linewidth=2, markersize=4)\n",
    "ax.scatter([end_local[1]], [end_local[0]], s=200, c='red', marker='*', edgecolors='black', linewidths=1.5)\n",
    "ax.set_title('Action-Label Path to Goal')\n",
    "ax.set_xlabel('Column Index'); ax.set_ylabel('Row Index'); ax.axis('image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate mic footprint across all valid positions in all files\n",
    "mic_hits_wall = 0\n",
    "for file_idx, info in enumerate(dataset.file_infos):\n",
    "    cg = info['cave_grid']\n",
    "    for (y, x) in info['valid']:\n",
    "        for dy, dx in MIC_OFFSETS:\n",
    "            my, mx = y + dy, x + dx\n",
    "            if not (0 <= my < cg.shape[0] and 0 <= mx < cg.shape[1]) or cg[my, mx] == 1:\n",
    "                mic_hits_wall += 1\n",
    "                break\n",
    "\n",
    "print(f\"Valid positions (all files): {len(dataset.valid_positions)}\")\n",
    "print(f\"Positions where any mic would hit a wall: {mic_hits_wall}\")\n",
    "assert mic_hits_wall == 0, \"Some mic locations fall on walls; check MIC_OFFSETS or valid_positions logic\"\n",
    "\n",
    "import random\n",
    "rng = random.Random(0)\n",
    "samples = rng.sample(dataset.valid_positions, min(5, len(dataset.valid_positions)))\n",
    "print(\"Sampled positions (file, y, x): action\")\n",
    "for file_idx, y, x in samples:\n",
    "    a = dataset.file_infos[file_idx]['action_grid'][y, x]\n",
    "    print(f\"  (file {file_idx}, {y}, {x}): {a.upper()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create DataLoader\n",
    "\n",
    "Prepare PyTorch DataLoader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training is handled in 03_Training.ipynb.\n",
    "# This notebook focuses on dataset inspection and visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compute Class Weights for Training\n",
    "\n",
    "To handle class imbalance (STOP is rare), compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weight computation is performed in 03_Training.ipynb using compute_class_distribution/weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Dataset Ready for Training!\n",
    "\n",
    "**What we have:**\n",
    "- \u2713 PyTorch Dataset with 3x3 footprint validation\n",
    "- \u2713 DataLoaders for train/val splits\n",
    "- \u2713 Action distribution analysis\n",
    "- \u2713 Class weights to handle imbalance\n",
    "- \u2713 Verified 8-mic data extraction\n",
    "\n",
    "**Next Steps:**\n",
    "1. Design neural network architecture (CNN/RNN)\n",
    "2. Implement training loop with class weights\n",
    "3. Monitor per-class accuracy (especially STOP)\n",
    "4. Evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose STOP coverage and visualize the first problematic file (if any)\n",
    "bad = []\n",
    "r = AGENT_RADIUS\n",
    "\n",
    "for i, info in enumerate(dataset.file_infos):\n",
    "    cg = info['cave_grid']\n",
    "    ag = info['action_grid']\n",
    "    y, x = info['end_pos']\n",
    "    label = ag[y, x]\n",
    "    if isinstance(label, bytes):\n",
    "        label = label.decode('utf-8')\n",
    "    is_stop = (label == 'stop')\n",
    "    footprint_ok = (\n",
    "        y - r >= 0 and y + r < cg.shape[0] and\n",
    "        x - r >= 0 and x + r < cg.shape[1] and\n",
    "        np.all(cg[y - r:y + r + 1, x - r:x + r + 1] == 0)\n",
    "    )\n",
    "    stop_in_valid = any((y == vy and x == vx) for vy, vx in info['valid'])\n",
    "    if not (is_stop and footprint_ok and stop_in_valid):\n",
    "        bad.append((i, is_stop, footprint_ok, stop_in_valid, (y, x), info['path'].name))\n",
    "\n",
    "print(f\"Files with STOP missing from valid_positions: {len(bad)}\")\n",
    "if bad:\n",
    "    print(\"First few:\", bad[:5])\n",
    "\n",
    "# Visualize the first bad file (if any)\n",
    "if bad:\n",
    "    idx, is_stop, footprint_ok, stop_in_valid, (y, x), fname = bad[0]\n",
    "    info = dataset.file_infos[idx]\n",
    "    cg = info['cave_grid']\n",
    "    ag = info['action_grid']\n",
    "    if isinstance(ag[y, x], bytes):\n",
    "        ag = np.vectorize(lambda t: t.decode('utf-8') if isinstance(t, bytes) else t)(ag)\n",
    "\n",
    "    print(f\"\\nInspecting file #{idx}: {fname}\")\n",
    "    print(f\"end_pos={info['end_pos']}, label_at_end={ag[y, x]}, footprint_ok={footprint_ok}, stop_in_valid={stop_in_valid}\")\n",
    "\n",
    "    from matplotlib.patches import Rectangle\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.imshow(cg, origin='upper', cmap='binary', alpha=0.8)\n",
    "    ax.scatter([info['end_pos'][1]], [info['end_pos'][0]], c='red', marker='*', s=200, edgecolors='black')\n",
    "    rect = Rectangle((x - r - 0.5, y - r - 0.5), 2 * r + 1, 2 * r + 1,\n",
    "                     linewidth=3, edgecolor='blue', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.set_title(f\"{fname} | STOP label: {ag[y, x]} | footprint_ok={footprint_ok}\")\n",
    "    ax.axis('image')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}