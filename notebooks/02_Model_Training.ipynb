{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Navigation - Model Training\n",
    "\n",
    "## Training Pipeline Overview\n",
    "\n",
    "**Task**: Predict optimal navigation action from acoustic sensor data\n",
    "\n",
    "### Agent Setup:\n",
    "- Agent occupies center of 3x3 grid cell\n",
    "- 8 microphones arranged in circle around agent (1 cell radius)\n",
    "- Each microphone records pressure time-series\n",
    "- **CRITICAL**: No part of 3x3 agent footprint can be inside walls!\n",
    "\n",
    "### Training Approach:\n",
    "1. Sample agent positions from navigable cave space (ensuring 3x3 validity)\n",
    "2. Extract 8-mic acoustic data at each position\n",
    "3. Predict action: STOP, UP, DOWN, LEFT, RIGHT\n",
    "4. Handle class imbalance (STOP is rarer than movement actions)\n",
    "\n",
    "### This Notebook:\n",
    "1. Load HDF5 dataset\n",
    "2. Create proper PyTorch DataLoader with 3x3 validation\n",
    "3. Visualize data distribution (action balance, agent positions)\n",
    "4. Show sample agent with 8-mic array\n",
    "5. Prepare for model training (next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n",
      "PyTorch version: 2.9.1+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset path\nDATASET_PATH = Path('../dataset/acoustic_cave_dataset.h5')\n\n# Agent configuration\nAGENT_RADIUS = 1  # 3x3 grid means radius of 1 cell from center\nNUM_MICS = 8      # 8 microphones in circular array\n\n# Action mapping: string labels -> numeric labels\nACTION_MAP = {\n    'stop': 0,\n    'up': 1,\n    'down': 2,\n    'left': 3,\n    'right': 4,\n    '': -1  # Invalid/wall\n}\n\n# Model output classes\nACTION_NAMES = ['STOP', 'UP', 'DOWN', 'LEFT', 'RIGHT']\nNUM_CLASSES = len(ACTION_NAMES)\n\n# Microphone positions (relative to agent center)\nMIC_OFFSETS = [\n    (0, 1),   # Right\n    (1, 1),   # Down-right\n    (1, 0),   # Down\n    (1, -1),  # Down-left\n    (0, -1),  # Left\n    (-1, -1), # Up-left\n    (-1, 0),  # Up\n    (-1, 1)   # Up-right\n]\n\nprint(f\"Dataset: {DATASET_PATH}\")\nprint(f\"Agent footprint: {2*AGENT_RADIUS+1}x{2*AGENT_RADIUS+1} = {(2*AGENT_RADIUS+1)**2} cells\")\nprint(f\"Microphones: {NUM_MICS}\")\nprint(f\"Actions: {NUM_CLASSES} classes - {ACTION_NAMES}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load HDF5 dataset\nprint(\"Loading dataset...\")\nwith h5py.File(DATASET_PATH, 'r') as f:\n    print(f\"\\nAvailable scenes: {list(f.keys())}\")\n    \n    # Load first scene (cave_0001)\n    scene = f['cave_0001']\n    \n    print(f\"\\nScene datasets:\")\n    for key in scene.keys():\n        print(f\"  {key}: {scene[key].shape} ({scene[key].dtype})\")\n    \n    print(f\"\\nMetadata:\")\n    for key, value in scene.attrs.items():\n        print(f\"  {key}: {value}\")\n    \n    # Load data into memory\n    cave_grid = scene['cave_grid'][:]\n    action_grid = scene['action_grid'][:]  # Will be bytes (b'up', b'down', etc.)\n    pressure_field = scene['pressure_timeseries'][:]  # (Nx, Ny, Nt)\n    \n    # Metadata\n    start_pos = tuple(scene.attrs['start_position'])\n    end_pos = tuple(scene.attrs['end_position'])  # Goal = sound source\n    dt = scene.attrs['dt']\n    f0 = scene.attrs['frequency_hz']\n\n# Convert action_grid from bytes to strings\naction_grid_str = np.vectorize(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)(action_grid)\n\nNx, Ny, Nt = pressure_field.shape\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Loaded Cave Scene:\")\nprint(f\"  Grid size: {Nx}x{Ny}\")\nprint(f\"  Time steps: {Nt}\")\nprint(f\"  Sampling rate: {1/dt:.0f} Hz\")\nprint(f\"  Source frequency: {f0/1000:.1f} kHz\")\nprint(f\"  Start: {start_pos}\")\nprint(f\"  Goal: {end_pos}\")\nprint(f\"  Walls: {100*cave_grid.mean():.1f}%\")\nprint(f\"  Air: {100*(1-cave_grid.mean()):.1f}%\")\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Create PyTorch Dataset\n\n**Key Logic**:\n- Agent at (y, x) occupies 3x3 square centered at (y, x)\n- Extract 8-mic pressure time-series from surrounding cells\n- Label = action at center position\n- With 3x3 expansion system, actions only exist at valid centers (every 3rd cell)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class AcousticCaveDataset(Dataset):\n    \"\"\"\n    PyTorch Dataset for acoustic navigation in caves.\n    \n    Agent occupies 3x3 footprint (center + 8 surrounding cells).\n    Dataset validates that entire footprint is in navigable space (air).\n    \"\"\"\n    \n    def __init__(self, cave_grid, action_grid, pressure_field,\n                 agent_radius=1, mic_offsets=None, action_map=None):\n        \"\"\"\n        Args:\n            cave_grid: (Nx, Ny) binary grid (0=air, 1=wall)\n            action_grid: (Nx, Ny) string array ('up', 'down', 'left', 'right', 'stop')\n            pressure_field: (Nx, Ny, Nt) pressure time-series\n            agent_radius: Radius of agent footprint (1 = 3x3 grid)\n            mic_offsets: List of (dy, dx) tuples for microphone positions\n            action_map: Dict mapping action strings to integer labels\n        \"\"\"\n        self.cave_grid = cave_grid\n        self.action_grid = action_grid\n        self.pressure_field = pressure_field\n        self.agent_radius = agent_radius\n        self.mic_offsets = mic_offsets if mic_offsets else MIC_OFFSETS\n        self.action_map = action_map if action_map else ACTION_MAP\n        \n        self.Nx, self.Ny, self.Nt = pressure_field.shape\n        \n        # Find all valid agent positions (with 3x3 footprint validation)\n        self.valid_positions = self._find_valid_positions()\n        \n        print(f\"AcousticCaveDataset initialized:\")\n        print(f\"  Cave size: {self.Nx}x{self.Ny}\")\n        print(f\"  Agent footprint: {2*agent_radius+1}x{2*agent_radius+1}\")\n        print(f\"  Valid positions: {len(self.valid_positions)}\")\n        print(f\"  Microphones: {len(self.mic_offsets)}\")\n        print(f\"  Time steps per mic: {self.Nt}\")\n    \n    def _is_valid_footprint(self, y, x):\n        \"\"\"Check if 3x3 footprint centered at (y,x) is entirely in air.\"\"\"\n        r = self.agent_radius\n        \n        # Check bounds\n        if y - r < 0 or y + r >= self.Nx or x - r < 0 or x + r >= self.Ny:\n            return False\n        \n        # Check if all cells in 3x3 footprint are air (0)\n        footprint = self.cave_grid[y-r:y+r+1, x-r:x+r+1]\n        return np.all(footprint == 0)\n    \n    def _find_valid_positions(self):\n        \"\"\"Find all positions where action labels exist AND 3x3 footprint is valid.\"\"\"\n        valid = []\n        \n        for y in range(self.Nx):\n            for x in range(self.Ny):\n                # Check if action exists at this position\n                action_str = self.action_grid[y, x]\n                if action_str in self.action_map and action_str != '':\n                    # Validate 3x3 footprint is in air\n                    if self._is_valid_footprint(y, x):\n                        valid.append((y, x))\n        \n        return valid\n    \n    def __len__(self):\n        return len(self.valid_positions)\n    \n    def __getitem__(self, idx):\n        \"\"\"\n        Returns:\n            mic_data: (8, Nt) tensor - pressure time-series for 8 mics\n            action: int - action label (0-4)\n        \"\"\"\n        y, x = self.valid_positions[idx]\n        \n        # Extract 8-mic time-series\n        mic_data = []\n        for dy, dx in self.mic_offsets:\n            mic_y, mic_x = y + dy, x + dx\n            # Get pressure time-series at this mic location\n            pressure = self.pressure_field[mic_y, mic_x, :]\n            mic_data.append(pressure)\n        \n        mic_data = np.array(mic_data, dtype=np.float32)  # (8, Nt)\n        \n        # Get action label\n        action_str = self.action_grid[y, x]\n        action_label = self.action_map[action_str]\n        \n        return torch.from_numpy(mic_data), torch.tensor(action_label, dtype=torch.long)\n    \n    def get_action_distribution(self):\n        \"\"\"Compute action distribution across all valid positions.\"\"\"\n        action_counts = {i: 0 for i in range(NUM_CLASSES)}\n        \n        for y, x in self.valid_positions:\n            action_str = self.action_grid[y, x]\n            action_num = self.action_map[action_str]\n            action_counts[action_num] += 1\n        \n        # Convert to named dict\n        named_counts = {ACTION_NAMES[i].lower(): action_counts[i] for i in range(NUM_CLASSES)}\n        return Counter(named_counts)\n    \n    def get_sample_with_position(self, idx):\n        \"\"\"Get sample with position info (for visualization).\"\"\"\n        y, x = self.valid_positions[idx]\n        mic_data, action = self.__getitem__(idx)\n        return mic_data, action, (y, x)\n\n# Create dataset\ndataset = AcousticCaveDataset(\n    cave_grid=cave_grid,\n    action_grid=action_grid_str,\n    pressure_field=pressure_field,\n    agent_radius=AGENT_RADIUS,\n    mic_offsets=MIC_OFFSETS,\n    action_map=ACTION_MAP\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Action Distribution\n",
    "\n",
    "**Important**: STOP will be rarer than movement actions (only at goal).  \n",
    "We'll need to handle class imbalance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get action distribution\naction_dist = dataset.get_action_distribution()\n\nprint(\"Action Distribution:\")\nprint(\"=\"*50)\ntotal_samples = len(dataset)\n\nfor action_name in ACTION_NAMES:\n    action_str = action_name.lower()\n    count = action_dist.get(action_str, 0)\n    percentage = 100 * count / total_samples\n    print(f\"  {action_name:>5s}: {count:>5d} ({percentage:>5.2f}%)\")\n\nprint(\"=\"*50)\nprint(f\"  TOTAL: {total_samples:>5d} (100.00%)\")\n\n# Visualize distribution\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bar chart\ncounts = [action_dist.get(name.lower(), 0) for name in ACTION_NAMES]\ncolors = ['red', 'blue', 'cyan', 'orange', 'green']\nbars = axes[0].bar(ACTION_NAMES, counts, color=colors, alpha=0.7, edgecolor='black')\naxes[0].set_xlabel('Action', fontsize=12)\naxes[0].set_ylabel('Count', fontsize=12)\naxes[0].set_title('Action Distribution', fontsize=14, fontweight='bold')\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# Add value labels on bars\nfor bar, count in zip(bars, counts):\n    height = bar.get_height()\n    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n                f'{count}\\n({100*count/total_samples:.1f}%)',\n                ha='center', va='bottom', fontsize=10)\n\n# Pie chart\naxes[1].pie(counts, labels=ACTION_NAMES, autopct='%1.1f%%', \n           colors=colors, startangle=90, textprops={'fontsize': 11})\naxes[1].set_title('Action Distribution (Percentage)', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Class imbalance warning\nmin_count = min(counts) if counts else 0\nmax_count = max(counts) if counts else 0\nimbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n\nprint(f\"\\nClass Imbalance Analysis:\")\nif counts:\n    print(f\"  Min count: {min_count} ({ACTION_NAMES[counts.index(min_count)]})\")\n    print(f\"  Max count: {max_count} ({ACTION_NAMES[counts.index(max_count)]})\")\n    print(f\"  Imbalance ratio: {imbalance_ratio:.2f}x\")\n\nif imbalance_ratio > 5:\n    print(f\"  \u26a0\ufe0f  HIGH IMBALANCE! Consider using class weights during training.\")\nelif imbalance_ratio > 2:\n    print(f\"  \u26a0\ufe0f  MODERATE IMBALANCE. Monitor per-class performance.\")\nelse:\n    print(f\"  \u2713 Balanced classes.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Visualize Valid Agent Positions\n\nShow where agents can be placed (3x3 expansion guarantees all are valid)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create valid position mask\nvalid_mask = np.zeros_like(cave_grid)\nfor y, x in dataset.valid_positions:\n    valid_mask[y, x] = 1\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Cave layout\naxes[0].imshow(cave_grid, origin='upper', cmap='binary')\naxes[0].scatter([end_pos[1]], [end_pos[0]], s=200, c='red', marker='*',\n               edgecolors='black', linewidths=2, label='Goal', zorder=10)\naxes[0].set_title(f'Cave Layout ({Nx}x{Ny})', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('X')\naxes[0].set_ylabel('Y')\naxes[0].legend()\naxes[0].axis('image')\n\n# Valid agent positions\naxes[1].imshow(valid_mask, origin='upper', cmap='Greens', alpha=0.6)\naxes[1].contour(cave_grid, levels=[0.5], colors='black', linewidths=1)\naxes[1].scatter([end_pos[1]], [end_pos[0]], s=200, c='red', marker='*',\n               edgecolors='black', linewidths=2, label='Goal', zorder=10)\naxes[1].set_title(f'Valid Agent Positions ({len(dataset.valid_positions)} total)', \n                 fontsize=14, fontweight='bold')\naxes[1].set_xlabel('X')\naxes[1].set_ylabel('Y')\naxes[1].legend()\naxes[1].axis('image')\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Valid agent positions: {len(dataset.valid_positions)} / {(Nx*Ny)} total cells\")\nprint(f\"Coverage: {100*len(dataset.valid_positions)/(Nx*Ny):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Agent with 8-Mic Array\n",
    "\n",
    "Pick a random agent position and show:\n",
    "- 3x3 footprint\n",
    "- 8 microphone positions\n",
    "- Pressure time-series at each mic\n",
    "- Action label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pick a random sample\nsample_idx = np.random.randint(0, len(dataset))\nmic_data, action, (agent_y, agent_x) = dataset.get_sample_with_position(sample_idx)\n\naction_name = ACTION_NAMES[action.item()]\n\nprint(f\"Sample {sample_idx}:\")\nprint(f\"  Agent position: ({agent_y}, {agent_x})\")\nprint(f\"  Action: {action_name}\")\nprint(f\"  Mic data shape: {mic_data.shape}\")\nprint(f\"  Cave grid at agent: {cave_grid[agent_y, agent_x]} (should be 0=air)\")\n\n# Verify 3x3 footprint\nr = AGENT_RADIUS\nfootprint = cave_grid[agent_y-r:agent_y+r+1, agent_x-r:agent_x+r+1]\nprint(f\"  3x3 footprint all air: {np.all(footprint == 0)}\")\n\n# Create comprehensive visualization\nfig = plt.figure(figsize=(18, 12))\ngs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n\n# 1. Agent position in FULL cave (no zoom)\nax1 = fig.add_subplot(gs[0, 0])\nax1.imshow(cave_grid.T, origin='lower', cmap='binary', alpha=0.6)\nax1.contour(cave_grid.T, levels=[0.5], colors='black', linewidths=1)\n\n# Draw 3x3 footprint\nfrom matplotlib.patches import Rectangle\nrect = Rectangle((agent_y-r-0.5, agent_x-r-0.5), 2*r+1, 2*r+1, \n                linewidth=3, edgecolor='blue', facecolor='blue', alpha=0.2)\nax1.add_patch(rect)\n\n# Agent center\nax1.scatter([agent_y], [agent_x], s=300, c='blue', marker='o',\n           edgecolors='white', linewidths=2, label='Agent', zorder=10)\n\n# 8 microphones\nmic_ys = [agent_y + dy for dy, dx in MIC_OFFSETS]\nmic_xs = [agent_x + dx for dy, dx in MIC_OFFSETS]\nax1.scatter(mic_ys, mic_xs, s=100, c='lime', marker='^',\n           edgecolors='black', linewidths=1, label='Mics', zorder=9)\n\n# Goal\nax1.scatter([end_pos[0]], [end_pos[1]], s=200, c='red', marker='*',\n           edgecolors='black', linewidths=1, label='Goal', zorder=8)\n\nax1.set_title(f'Agent Position (FULL CAVE)\\nAction: {action_name}', fontsize=12, fontweight='bold')\nax1.set_xlabel('Row')\nax1.set_ylabel('Col')\nax1.legend(loc='upper right', fontsize=8)\nax1.axis('image')\n# NO xlim/ylim - show full cave!\n\n# 2. 3x3 Footprint Detail\nax2 = fig.add_subplot(gs[0, 1])\nax2.imshow(footprint.T, origin='lower', cmap='binary', alpha=0.6)\nax2.scatter([r], [r], s=300, c='blue', marker='o',\n           edgecolors='white', linewidths=2, label='Agent')\nmic_ys_local = [r + dy for dy, dx in MIC_OFFSETS]\nmic_xs_local = [r + dx for dy, dx in MIC_OFFSETS]\nax2.scatter(mic_ys_local, mic_xs_local, s=100, c='lime', marker='^',\n           edgecolors='black', linewidths=1, label='Mics')\nax2.set_title(f'3x3 Footprint Detail\\n(All air = {footprint.sum() == 0})', \n             fontsize=12, fontweight='bold')\nax2.set_xlabel('Local Row')\nax2.set_ylabel('Local Col')\nax2.legend(fontsize=8)\nax2.axis('image')\n\n# 3. Mic data statistics\nax3 = fig.add_subplot(gs[0, 2:])\nmic_rms = np.sqrt(np.mean(mic_data.numpy()**2, axis=1))\nmic_peak = np.max(np.abs(mic_data.numpy()), axis=1)\nmic_labels = ['R', 'DR', 'D', 'DL', 'L', 'UL', 'U', 'UR']\n\nx_pos = np.arange(8)\nwidth = 0.35\nax3.bar(x_pos - width/2, mic_rms, width, label='RMS', alpha=0.7)\nax3.bar(x_pos + width/2, mic_peak, width, label='Peak', alpha=0.7)\nax3.set_xlabel('Microphone')\nax3.set_ylabel('Pressure')\nax3.set_title('Microphone Statistics', fontsize=12, fontweight='bold')\nax3.set_xticks(x_pos)\nax3.set_xticklabels(mic_labels)\nax3.legend()\nax3.grid(True, alpha=0.3, axis='y')\n\n# 4-11. Time-series for each mic\ntime_array = np.arange(Nt) * dt * 1000  # Convert to ms\n\nfor i in range(8):\n    row = 1 + i // 4\n    col = i % 4\n    ax = fig.add_subplot(gs[row, col])\n    \n    ax.plot(time_array, mic_data[i].numpy(), linewidth=1)\n    ax.set_title(f'Mic {i+1} ({mic_labels[i]})', fontsize=10, fontweight='bold')\n    ax.set_xlabel('Time (ms)', fontsize=8)\n    ax.set_ylabel('Pressure', fontsize=8)\n    ax.grid(True, alpha=0.3)\n    ax.tick_params(labelsize=8)\n\nplt.suptitle(f'Agent Sample - Position ({agent_y},{agent_x}) - Action: {action_name}',\n            fontsize=16, fontweight='bold', y=0.995)\nplt.show()\n\nprint(f\"\\nMicrophone Data Summary:\")\nprint(f\"  Shape: {mic_data.shape} (8 mics \u00d7 {Nt} timesteps)\")\nprint(f\"  RMS range: [{mic_rms.min():.6f}, {mic_rms.max():.6f}]\")\nprint(f\"  Peak range: [{mic_peak.min():.6f}, {mic_peak.max():.6f}]\")"
  },
  {
   "cell_type": "code",
   "source": [
    "# FULL MAP VISUALIZATION - Agent, Mics, and Goal\n",
    "# This shows the complete cave with the agent's 3x3 footprint clearly visible\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Left: Full cave with agent (origin upper so y increases downward, matching action grid)\n",
    "ax = axes[0]\n",
    "ax.imshow(cave_grid, origin='upper', cmap='binary', alpha=0.8)\n",
    "ax.contour(cave_grid, levels=[0.5], colors='gray', linewidths=1.5, alpha=0.5)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "r = AGENT_RADIUS\n",
    "rect = Rectangle((agent_x - r - 0.5, agent_y - r - 0.5), 2*r + 1, 2*r + 1,\n",
    "                linewidth=4, edgecolor='blue', facecolor='blue', alpha=0.3, label='3x3 Footprint')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "ax.scatter([agent_x], [agent_y], s=500, c='blue', marker='o',\n",
    "           edgecolors='white', linewidths=3, label='Agent', zorder=10)\n",
    "\n",
    "# Mic positions; only draw mics that are in air\n",
    "mic_ys = [agent_y + dy for dy, dx in MIC_OFFSETS]\n",
    "mic_xs = [agent_x + dx for dy, dx in MIC_OFFSETS]\n",
    "mic_in_air = [(mx, my) for mx, my in zip(mic_xs, mic_ys) if 0 <= my < Nx and 0 <= mx < Ny and cave_grid[int(my), int(mx)] == 0]\n",
    "if mic_in_air:\n",
    "    ax.scatter([mx for mx,_ in mic_in_air], [my for _,my in mic_in_air], s=150, c='lime', marker='^',\n",
    "               edgecolors='black', linewidths=2, label='8 Microphones (air only)', zorder=9)\n",
    "\n",
    "ax.scatter([end_pos[1]], [end_pos[0]], s=400, c='red', marker='*',\n",
    "           edgecolors='black', linewidths=2, label='Goal (Sound Source)', zorder=8)\n",
    "\n",
    "ax.set_title(f'Full Cave Map - Agent at ({agent_y},{agent_x})\n",
    "Action: {action_name}',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Column Index', fontsize=12)\n",
    "ax.set_ylabel('Row Index', fontsize=12)\n",
    "ax.legend(loc='upper left', fontsize=10, framealpha=0.9)\n",
    "ax.axis('image')\n",
    "ax.grid(True, alpha=0.2, linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Right: Zoomed view around agent (same origin)\n",
    "ax = axes[1]\n",
    "zoom_radius = 10\n",
    "y_min = max(0, agent_y - zoom_radius)\n",
    "y_max = min(Nx, agent_y + zoom_radius + 1)\n",
    "x_min = max(0, agent_x - zoom_radius)\n",
    "x_max = min(Ny, agent_x + zoom_radius + 1)\n",
    "\n",
    "cave_zoom = cave_grid[y_min:y_max, x_min:x_max]\n",
    "extent_zoom = [x_min - 0.5, x_max - 0.5, y_min - 0.5, y_max - 0.5]\n",
    "ax.imshow(cave_zoom, origin='upper', cmap='binary', alpha=0.8, extent=extent_zoom)\n",
    "\n",
    "rect_zoom = Rectangle((agent_x - r - 0.5, agent_y - r - 0.5), 2*r + 1, 2*r + 1,\n",
    "                      linewidth=4, edgecolor='blue', facecolor='blue', alpha=0.3)\n",
    "ax.add_patch(rect_zoom)\n",
    "\n",
    "if mic_in_air:\n",
    "    ax.scatter([mx for mx,_ in mic_in_air], [my for _,my in mic_in_air], s=150, c='lime', marker='^',\n",
    "               edgecolors='black', linewidths=2, label='Mics (air only)', zorder=9)\n",
    "\n",
    "mic_labels = ['R', 'DR', 'D', 'DL', 'L', 'UL', 'U', 'UR']\n",
    "for label, (mx, my) in zip(mic_labels, zip(mic_xs, mic_ys)):\n",
    "    if 0 <= my < Nx and 0 <= mx < Ny and cave_grid[int(my), int(mx)] == 0:\n",
    "        ax.text(mx, my - 0.6, label, fontsize=9, fontweight='bold',\n",
    "                ha='center', va='top', color='darkgreen',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "ax.set_title(f'Zoomed View (\u00b1{zoom_radius} cells)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Column Index', fontsize=12)\n",
    "ax.set_ylabel('Row Index', fontsize=12)\n",
    "ax.legend(loc='upper left', fontsize=10, framealpha=0.9)\n",
    "ax.axis('image')\n",
    "ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print summary\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"AGENT VERIFICATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Agent Position: ({agent_y}, {agent_x})\")\n",
    "print(f\"Cave grid at agent: {cave_grid[agent_y, agent_x]} (0=air, 1=wall)\")\n",
    "print(f\"3x3 footprint all air: {np.all(footprint == 0)}\")\n",
    "print(f\"Action label: {action_name}\")\n",
    "print(f\"Goal Position: {end_pos}\")\n",
    "print(f\"Distance to goal: {np.sqrt((agent_y-end_pos[0])**2 + (agent_x-end_pos[1])**2):.1f} cells\")\n",
    "print(f\"{'='*60}\")\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Follow action labels from current agent position to goal\n",
    "moves = {'up': (-1,0), 'down': (1,0), 'left': (0,-1), 'right': (0,1), 'stop': (0,0)}\n",
    "\n",
    "def follow_path(start_y, start_x, max_steps=2000):\n",
    "    path = [(int(start_y), int(start_x))]\n",
    "    r, c = start_y, start_x\n",
    "    for step in range(max_steps):\n",
    "        a = action_grid_str[r, c]\n",
    "        if a == 'stop':\n",
    "            return True, path\n",
    "        if a not in moves:\n",
    "            return False, path\n",
    "        dr, dc = moves[a]\n",
    "        nr, nc = r + dr, c + dc\n",
    "        if not (0 <= nr < Nx and 0 <= nc < Ny):\n",
    "            return False, path\n",
    "        if cave_grid[nr, nc] == 1:\n",
    "            return False, path\n",
    "        r, c = nr, nc\n",
    "        path.append((int(r), int(c)))\n",
    "    return False, path\n",
    "\n",
    "ok, path = follow_path(agent_y, agent_x)\n",
    "print(f\"Path follow result: {'SUCCESS' if ok else 'FAIL'}, steps={len(path)-1}, end={path[-1]}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.imshow(cave_grid, origin='upper', cmap='binary', alpha=0.8)\n",
    "ys = [p[0] for p in path]; xs = [p[1] for p in path]\n",
    "ax.plot(xs, ys, '-o', color='lime' if ok else 'red', linewidth=2, markersize=4)\n",
    "ax.scatter([end_pos[1]], [end_pos[0]], s=200, c='red', marker='*', edgecolors='black', linewidths=1.5)\n",
    "ax.set_title('Action-Label Path to Goal')\n",
    "ax.set_xlabel('Column Index'); ax.set_ylabel('Row Index'); ax.axis('image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Validate mic footprint across all valid positions and sample a few\n",
    "mic_hits_wall = 0\n",
    "for (y, x) in dataset.valid_positions:\n",
    "    for dy, dx in MIC_OFFSETS:\n",
    "        my, mx = y + dy, x + dx\n",
    "        if not (0 <= my < Nx and 0 <= mx < Ny) or cave_grid[my, mx] == 1:\n",
    "            mic_hits_wall += 1\n",
    "            break\n",
    "\n",
    "print(f\"Valid positions: {len(dataset.valid_positions)}\")\n",
    "print(f\"Positions where any mic would hit a wall: {mic_hits_wall}\")\n",
    "assert mic_hits_wall == 0, \"Some mic locations fall on walls; check MIC_OFFSETS or valid_positions logic\"\n",
    "\n",
    "import random\n",
    "rng = random.Random(0)\n",
    "samples = rng.sample(dataset.valid_positions, min(5, len(dataset.valid_positions)))\n",
    "print(\"\n",
    "Sampled positions (y, x): action, dist_to_goal\")\n",
    "for y, x in samples:\n",
    "    action = action_grid_str[y, x]\n",
    "    dist = ((y - end_pos[0])**2 + (x - end_pos[1])**2) ** 0.5\n",
    "    print(f\"  ({y}, {x}): {action.upper()}, dist={dist:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create DataLoader\n",
    "\n",
    "Prepare PyTorch DataLoader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader configuration\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SPLIT = 0.8\n",
    "NUM_WORKERS = 0  # Use 0 for Windows, 4+ for Linux/Mac\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(TRAIN_SPLIT * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Dataset Split:\")\n",
    "print(f\"  Training: {len(train_dataset)} samples ({100*train_size/len(dataset):.0f}%)\")\n",
    "print(f\"  Validation: {len(val_dataset)} samples ({100*val_size/len(dataset):.0f}%)\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Test batch loading\n",
    "sample_batch_data, sample_batch_actions = next(iter(train_loader))\n",
    "print(f\"\\nSample Batch:\")\n",
    "print(f\"  Data shape: {sample_batch_data.shape}\")\n",
    "print(f\"  Actions shape: {sample_batch_actions.shape}\")\n",
    "print(f\"  Actions in batch: {sample_batch_actions.tolist()[:10]}...\")\n",
    "\n",
    "# Action distribution in batch\n",
    "batch_action_counts = Counter(sample_batch_actions.numpy())\n",
    "print(f\"\\nAction distribution in sample batch:\")\n",
    "for i, name in enumerate(ACTION_NAMES):\n",
    "    count = batch_action_counts.get(i, 0)\n",
    "    print(f\"  {name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compute Class Weights for Training\n",
    "\n",
    "To handle class imbalance (STOP is rare), compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights (inverse frequency)\n",
    "action_counts = np.array([action_dist.get(name.lower(), 1) for name in ACTION_NAMES])\n",
    "class_weights = 1.0 / action_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(ACTION_NAMES)  # Normalize\n",
    "\n",
    "class_weights_tensor = torch.FloatTensor(class_weights)\n",
    "\n",
    "print(\"Class Weights (for loss function):\")\n",
    "print(\"=\"*50)\n",
    "for name, weight in zip(ACTION_NAMES, class_weights):\n",
    "    print(f\"  {name:>5s}: {weight:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nTo use in training:\")\n",
    "print(f\"  criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\")\n",
    "\n",
    "# Save for later use\n",
    "torch.save({\n",
    "    'class_weights': class_weights_tensor,\n",
    "    'action_names': ACTION_NAMES,\n",
    "    'action_map': ACTION_MAP,\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(dataset),\n",
    "        'action_distribution': dict(action_dist),\n",
    "        'grid_size': (Nx, Ny),\n",
    "        'time_steps': Nt,\n",
    "        'sampling_rate': 1/dt,\n",
    "        'frequency': f0\n",
    "    }\n",
    "}, '../dataset/dataset_info.pt')\n",
    "\n",
    "print(f\"\\n\u2713 Dataset info saved to ../dataset/dataset_info.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Dataset Ready for Training!\n",
    "\n",
    "**What we have:**\n",
    "- \u2713 PyTorch Dataset with 3x3 footprint validation\n",
    "- \u2713 DataLoaders for train/val splits\n",
    "- \u2713 Action distribution analysis\n",
    "- \u2713 Class weights to handle imbalance\n",
    "- \u2713 Verified 8-mic data extraction\n",
    "\n",
    "**Next Steps:**\n",
    "1. Design neural network architecture (CNN/RNN)\n",
    "2. Implement training loop with class weights\n",
    "3. Monitor per-class accuracy (especially STOP)\n",
    "4. Evaluate on validation set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}